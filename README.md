# BIG-DATA-ANALYSIS
*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: DEEP MALVANKAR

*INTERN ID*:CT04DR2394

*DOMAIN*: DATA ANALYTICS

*DURATION*: 4 WEEKS

*MENTOR*: NEELA SANTOSH
**PERFORM ANALYSIS ON A LARGE DATASET USING TOOLS LIKE PYSPA OR DASK TO DEMONSTRATE SCALABILITY.
To demonstrate how big-data tools such as Dask or PySpark handle and process large datasets efficiently by performing distributed data analysis. The goal is to show how these tools scale beyond the limits of normal Python/Pandas, and to extract meaningful insights from a large dataset.A big dataset (e.g., 100,000+ rows) was created to simulate real-world big-data scenarios.
It included:user_id ,age ,purchase amount number of items, location ,timestamps This dataset is large enough to demonstrate why we need distributed computing.

*OUTPUT
<img width="506" height="402" alt="Image" src="https://github.com/user-attachments/assets/e5a2971d-068f-48b2-ba07-d0d9d50d8f30" />
